{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USu2ano8Faa7"
   },
   "source": [
    "# PyTorch Classification Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZUXDU3sqDfON"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch nn.Module\n",
    "* 엄격한 객체지향(object-oriented)설계를 따라 확장 및 재사용이 class를 통해 torch.nn.Module 상속\n",
    "* `__init__()` : 사용될 submodule들과 함수들을 정의\n",
    "* `forward()` : 입력에 대한 output 계산, 이후 output에 직접 `backward()`를 불러 backpropagation 수행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GK4D6o7I22So"
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, activation=None):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.a = torch.nn.Parameter(torch.Tensor([np.random.normal()]))\n",
    "        self.b = torch.nn.Parameter(torch.Tensor([np.random.normal()]))\n",
    "        self.c = torch.nn.Parameter(torch.Tensor([np.random.normal()]))\n",
    "        if activation is not None:\n",
    "            self.activate = activation\n",
    "        else:\n",
    "            self.activate = torch.sigmoid\n",
    "  \n",
    "    def forward(self, x):\n",
    "        return self.activate(self.a * x[:,0] + self.b * x[:,1] - self.c).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1CqmxX7MHRqr"
   },
   "outputs": [],
   "source": [
    "class DataGenerator(Dataset):\n",
    "    def __init__(self, type_, length, std=0.08):\n",
    "        self.length = length\n",
    "        if type_ == 'and':\n",
    "            self.val_l = [0, 0, 0, 1]\n",
    "        elif type_ == 'or':\n",
    "            self.val_l = [0, 1, 1, 1]\n",
    "        elif type_ == 'xor':\n",
    "            self.val_l = [0, 1, 1, 0]\n",
    "        else:\n",
    "            self.val_l = [0, 0, 0, 0]\n",
    "     \n",
    "        self.dataset = []\n",
    "        for i in range(length):\n",
    "            x = np.random.normal(i%2, std)      #0,1,0,1,0,1,0,1,...\n",
    "            y = np.random.normal((i//2)%2, std) #0,0,1,1,0,0,1,1,...\n",
    "            val = self.val_l[i%4]\n",
    "            self.dataset.append((x, y, val))\n",
    "      \n",
    "    def get_dataset(self):\n",
    "        return self.dataset\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x, y, val = self.dataset[idx]\n",
    "        return (torch.Tensor([x, y]), torch.Tensor([val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZgNCHs4IF9L"
   },
   "outputs": [],
   "source": [
    "DATASET = DataGenerator('and', 1000)\n",
    "lr = 0.01 # learning rate\n",
    "batch_size = 20\n",
    "num_epochs = 30\n",
    "num_workers = 4\n",
    "\n",
    "params = {\n",
    "    'batch_size' : batch_size,\n",
    "    'shuffle' : True,\n",
    "    'num_workers' : num_workers\n",
    "}\n",
    "\n",
    "dataloader = DataLoader(DATASET, **params)\n",
    "model = Classifier().cuda()\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1crD9BAMIuCz",
    "outputId": "033f69d5-2b4d-486b-c652-920e05678a8a"
   },
   "outputs": [],
   "source": [
    "def show(model):\n",
    "    for item in DATASET.get_dataset():\n",
    "        x, y, val = item\n",
    "        if val == 1:\n",
    "            plt.scatter(x, y, c='red', s=10)\n",
    "        else:\n",
    "            plt.scatter(x, y, c='blue', s=10)\n",
    "    t = torch.arange(70,dtype=torch.float32)*0.02-0.2\n",
    "    x = t.unsqueeze(0).repeat(70,1).unsqueeze(-1)\n",
    "    y = t.unsqueeze(1).repeat(1,70).unsqueeze(-1)\n",
    "    data = torch.cat((x,y),-1).view(-1,2)\n",
    "    with torch.no_grad():\n",
    "        val = (model(data.cuda())).cpu()\n",
    "    colors = torch.cat((val,torch.zeros_like(val),1-val),-1).numpy()\n",
    "    plt.scatter(data.numpy()[:,0],data.numpy()[:,1], c=colors, s=1)\n",
    "    plt.show()\n",
    "\n",
    "show(model)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for x, val in dataloader: \n",
    "        x = x.cuda()\n",
    "        val = val.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        val_ =  model(x)\n",
    "        # loss 계산\n",
    "        loss = torch.sum(torch.pow(val - val_, 2))\n",
    "        # gradient 계산\n",
    "        loss.backward()\n",
    "        # update 적용\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(\"Loss : {:.5f}\".format(total_loss / len(DATASET)))\n",
    "    if epoch % 10  == 9:\n",
    "        model.eval()\n",
    "        show(model)\n",
    "        model.train()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "Logic Gate",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
