{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-sbkFbNUAKyK"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import Compose,ToTensor\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2nLnUERGaL_"
      },
      "source": [
        "#### DNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nV9KcFU1FKsR"
      },
      "outputs": [],
      "source": [
        "class MNISTDNN(nn.Module):\n",
        "    def __init__(self,IMG_SIZE=28):\n",
        "        super(MNISTDNN,self).__init__()\n",
        "        self.fc1 = nn.Linear(IMG_SIZE*IMG_SIZE,32)\n",
        "        self.BN1 = torch.nn.BatchNorm1d(32)\n",
        "        self.fc2 = nn.Linear(32,10)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.BN1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = torch.softmax(x,dim=-1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNCKxXJwGdN4"
      },
      "source": [
        "#### CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CvofB0pnGfHM"
      },
      "outputs": [],
      "source": [
        "class MNISTCNN(nn.Module):\n",
        "    def __init__(self,IMG_SIZE=28):\n",
        "        super(MNISTCNN,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1,8,5,stride=2)\n",
        "        self.BN1 = torch.nn.BatchNorm2d(8)\n",
        "        self.conv2 = nn.Conv2d(8,8,5,stride=2)\n",
        "        self.BN2 = torch.nn.BatchNorm2d(8)\n",
        "        self.conv3 = nn.Conv2d(8,8,3,stride=1)\n",
        "        self.fc = nn.Linear(8*2*2,10)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.BN1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.BN2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = x.view(-1,8*2*2)\n",
        "        x = self.fc(x)\n",
        "        x = torch.softmax(x,dim=-1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zyvh6IKYZcdi"
      },
      "source": [
        "#### Util function for calculating accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7YSzoolPQqIL"
      },
      "outputs": [],
      "source": [
        "def compute_acc(argmax,y):\n",
        "    count = 0\n",
        "    for i in range(len(argmax)):\n",
        "        if argmax[i]==y[i]:\n",
        "            count+=1\n",
        "    return count / len(argmax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7KNrp6hGXWI"
      },
      "source": [
        "#### hyperparameters & datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vny-hSnYGOx5"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 28\n",
        "BATCH_SIZE = 256\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_EPOCHES = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IpnCYlVHBuSW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST_models/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:03<00:00, 3283723.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST_models/MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST_models/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST_models/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 147502.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST_models/MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST_models/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST_models/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:01<00:00, 1183499.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST_models/MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST_models/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST_models/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 3883899.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST_models/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST_models/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "transforms = Compose([\n",
        "    ToTensor(),\n",
        "])\n",
        "\n",
        "trainset = MNIST('./MNIST_models/',train=True,transform=transforms,download=True)\n",
        "testset = MNIST('./MNIST_models/',train=False,transform=transforms,download=True)\n",
        "\n",
        "args = {\n",
        "    'num_workers' : 1,\n",
        "    'batch_size' : BATCH_SIZE,\n",
        "    'shuffle' : True,\n",
        "}\n",
        "\n",
        "train_loader = DataLoader(trainset,**args)\n",
        "test_loader = DataLoader(testset,**args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw9IBUpYZPqb"
      },
      "source": [
        "####Training part(DNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPSsZM0uGs2z",
        "outputId": "c50f4a8e-e8f0-4922-a8cf-a0bf3c4fb93f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of parameters : 25514\n",
            "Epoch 1, Loss(train) : 1.579682664014399\n",
            "Epoch 2, Loss(train) : 1.437080874107778\n",
            "tensor([[1.6052e-04, 9.7494e-01, 2.2621e-03,  ..., 1.3216e-02, 1.3025e-03,\n",
            "         4.4931e-03],\n",
            "        [6.2200e-04, 1.1849e-03, 4.7773e-04,  ..., 1.8310e-04, 9.7208e-01,\n",
            "         1.4159e-03],\n",
            "        [3.3658e-05, 3.3361e-04, 9.9608e-01,  ..., 1.0234e-04, 3.7553e-05,\n",
            "         2.4834e-05],\n",
            "        ...,\n",
            "        [1.7853e-04, 1.4881e-05, 2.3797e-04,  ..., 2.5855e-05, 9.9546e-01,\n",
            "         3.8620e-05],\n",
            "        [8.3516e-06, 9.9745e-01, 4.7626e-05,  ..., 2.6870e-04, 2.9431e-04,\n",
            "         3.5997e-04],\n",
            "        [7.0744e-04, 2.7514e-04, 2.4541e-03,  ..., 1.4005e-03, 6.0840e-04,\n",
            "         3.2498e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "Acc(val) : 0.95703125\n",
            "Epoch 3, Loss(train) : 1.4089618208818138\n",
            "Epoch 4, Loss(train) : 1.3955695256590843\n",
            "tensor([[2.2614e-06, 6.5287e-09, 1.0239e-04,  ..., 6.9148e-07, 5.5957e-05,\n",
            "         3.4548e-08],\n",
            "        [3.7404e-03, 3.5711e-04, 1.8762e-04,  ..., 7.7685e-05, 9.6519e-01,\n",
            "         4.3540e-03],\n",
            "        [7.6071e-07, 9.9898e-01, 1.9284e-04,  ..., 6.4237e-04, 1.6716e-05,\n",
            "         6.2877e-06],\n",
            "        ...,\n",
            "        [1.3265e-08, 1.5007e-06, 1.8257e-06,  ..., 9.9995e-01, 3.8894e-05,\n",
            "         1.7253e-06],\n",
            "        [9.9687e-01, 2.5703e-05, 3.8624e-04,  ..., 1.8469e-05, 2.8188e-04,\n",
            "         2.9155e-05],\n",
            "        [7.7202e-05, 2.5645e-05, 8.0292e-06,  ..., 1.4868e-05, 7.6798e-04,\n",
            "         7.9244e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "Acc(val) : 0.94140625\n",
            "Epoch 5, Loss(train) : 1.3873361120931804\n"
          ]
        }
      ],
      "source": [
        "model = MNISTDNN(IMG_SIZE).cuda()\n",
        "\n",
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "num_params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "print(\"number of parameters : {}\".format(num_params))\n",
        "\n",
        "optimizer = Adam(model.parameters(),lr=LEARNING_RATE)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(NUM_EPOCHES):\n",
        "    tot_loss = 0.0\n",
        "\n",
        "    for x,y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        x = x.cuda().view(-1,IMG_SIZE*IMG_SIZE)\n",
        "        y_ = model(x)\n",
        "        loss = loss_fn(y_, y.cuda())\n",
        "        loss.backward()\n",
        "        tot_loss+=loss.item()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"Epoch {}, Loss(train) : {}\".format(epoch+1,tot_loss/BATCH_SIZE))\n",
        "    if epoch % 2 == 1:\n",
        "        x,y = next(iter(test_loader))\n",
        "        x = x.cuda().view(-1,IMG_SIZE*IMG_SIZE)\n",
        "        y_ = model(x)\n",
        "        print(y_)\n",
        "        _, argmax = torch.max(y_,dim=-1)\n",
        "        test_acc = compute_acc(argmax,y.numpy())\n",
        "\n",
        "        print(\"Acc(val) : {}\".format(test_acc))\n",
        "\n",
        "torch.save(model.state_dict(), \"./MNIST_models/DNN.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFVFgMyCP3-f",
        "outputId": "e0ea1489-1ec0-4077-f66e-643f646c3309"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(model.parameters())[3].requires_grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSCkeBPwUUz9",
        "outputId": "01d1cb7e-ab32-4b5c-c188-1993c3da73c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 784])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(model.parameters())[0].size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVgpiOZRTB12",
        "outputId": "35fcbe95-7b08-42b7-d822-6ae539368685"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25088"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.prod(list(model.parameters())[0].size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o16a0zkYQcq5",
        "outputId": "da505726-428c-44ae-9a2f-c7b5536ec13d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 784])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "torch.Size([10, 32])\n",
            "torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "# self.fc1(x) 784 * 32\n",
        "# F.relu(x) 32\n",
        "# self.BN1(x) 32\n",
        "# self.fc2(x) 10 * 32\n",
        "# torch.softmax(x,dim=-1) 10\n",
        "\n",
        "for i in model.parameters():\n",
        "  print(i.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyC_PAFPMPLw",
        "outputId": "0a6feb40-cdc2-47f6-c7bf-5b92229549d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75037/1102898388.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_test.load_state_dict(torch.load(\"./MNIST_models/DNN.pt\"))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acc(test) : 0.95703125\n"
          ]
        }
      ],
      "source": [
        "model_test = MNISTDNN(IMG_SIZE).cuda()\n",
        "model_test.load_state_dict(torch.load(\"./MNIST_models/DNN.pt\"))\n",
        "model_test.eval()\n",
        "x,y = next(iter(test_loader))\n",
        "x = x.cuda().view(-1,IMG_SIZE*IMG_SIZE)\n",
        "y_ = model_test(x)\n",
        "_, argmax = torch.max(y_,dim=-1)\n",
        "test_acc = compute_acc(argmax,y.numpy())\n",
        "\n",
        "print(\"Acc(test) : {}\".format(test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZlMbw_tZLT-"
      },
      "source": [
        "#### Training part(CNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_hp82IXWJ4z",
        "outputId": "f837fe60-b5c7-4457-c663-ab12059e66d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of parameters : 2762\n",
            "Epoch 1, Loss(train) : 1.6857146392576396\n",
            "Epoch 2, Loss(train) : 1.4118502708151937\n",
            "Acc(test) : 0.95703125\n",
            "Epoch 3, Loss(train) : 1.3880043840035796\n",
            "Epoch 4, Loss(train) : 1.3786680148914456\n",
            "Acc(test) : 0.9765625\n",
            "Epoch 5, Loss(train) : 1.3733413200825453\n"
          ]
        }
      ],
      "source": [
        "model = MNISTCNN(IMG_SIZE).cuda()\n",
        "\n",
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "num_params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "print(\"number of parameters : {}\".format(num_params))\n",
        "\n",
        "optimizer = Adam(model.parameters(),lr=LEARNING_RATE)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(NUM_EPOCHES):\n",
        "    tot_loss = 0.0\n",
        "\n",
        "    for x,y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        x = x.cuda()\n",
        "        y_ = model(x)\n",
        "        loss = loss_fn(y_, y.cuda())\n",
        "        loss.backward()\n",
        "        tot_loss+=loss.item()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"Epoch {}, Loss(train) : {}\".format(epoch+1,tot_loss/BATCH_SIZE))\n",
        "    if epoch % 2 == 1:\n",
        "        model.eval()\n",
        "\n",
        "        x,y = next(iter(test_loader))\n",
        "        x = x.cuda()\n",
        "        y_ = model(x)\n",
        "        _, argmax = torch.max(y_,dim=-1)\n",
        "        test_acc = compute_acc(argmax,y.numpy())\n",
        "\n",
        "        print(\"Acc(test) : {}\".format(test_acc))\n",
        "\n",
        "        model.train()\n",
        "\n",
        "torch.save(model.state_dict(), \"./MNIST_models/CNN.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xhN_wmbMR41",
        "outputId": "127fbd9f-bdf0-476c-8ad1-8b2cbe2ffcc6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_75037/3989002674.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_test.load_state_dict(torch.load(\"./MNIST_models/CNN.pt\"))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acc(test) : 0.9765625\n"
          ]
        }
      ],
      "source": [
        "model_test = MNISTCNN(IMG_SIZE).cuda()\n",
        "model_test.load_state_dict(torch.load(\"./MNIST_models/CNN.pt\"))\n",
        "model_test.eval()\n",
        "x,y = next(iter(test_loader))\n",
        "x = x.cuda()\n",
        "y_ = model_test(x)\n",
        "_, argmax = torch.max(y_,dim=-1)\n",
        "test_acc = compute_acc(argmax,y.numpy())\n",
        "\n",
        "print(\"Acc(test) : {}\".format(test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSMsL5fKVONu",
        "outputId": "83d5173c-2de7-4358-f7e6-1f754791c398"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 5, 5])\n",
            "torch.Size([8])\n",
            "torch.Size([8])\n",
            "torch.Size([8])\n",
            "torch.Size([8, 8, 5, 5])\n",
            "torch.Size([8])\n",
            "torch.Size([8])\n",
            "torch.Size([8])\n",
            "torch.Size([8, 8, 3, 3])\n",
            "torch.Size([8])\n",
            "torch.Size([10, 32])\n",
            "torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "for i in model.parameters():\n",
        "  print(i.size())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "name": "Lab2_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
